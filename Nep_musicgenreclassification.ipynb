{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#less go\nimport os\nos.getcwd()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-13T17:30:47.103728Z","iopub.execute_input":"2023-02-13T17:30:47.104215Z","iopub.status.idle":"2023-02-13T17:30:47.135647Z","shell.execute_reply.started":"2023-02-13T17:30:47.104135Z","shell.execute_reply":"2023-02-13T17:30:47.134633Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"print('les go')","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:30:47.137557Z","iopub.execute_input":"2023-02-13T17:30:47.137905Z","iopub.status.idle":"2023-02-13T17:30:47.144409Z","shell.execute_reply.started":"2023-02-13T17:30:47.137869Z","shell.execute_reply":"2023-02-13T17:30:47.143395Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"les go\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-02-13T11:06:29.076284Z","iopub.execute_input":"2023-02-13T11:06:29.076643Z","iopub.status.idle":"2023-02-13T11:06:29.081903Z","shell.execute_reply.started":"2023-02-13T11:06:29.076612Z","shell.execute_reply":"2023-02-13T11:06:29.080834Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!wandb login 31c7358e23c8522a5aece87ff899a31a639ef7d4\nimport wandb\nwandb.init(project=\"test\")","metadata":{"execution":{"iopub.status.busy":"2023-02-13T11:06:29.347989Z","iopub.execute_input":"2023-02-13T11:06:29.348345Z","iopub.status.idle":"2023-02-13T11:06:29.352796Z","shell.execute_reply.started":"2023-02-13T11:06:29.348316Z","shell.execute_reply":"2023-02-13T11:06:29.351552Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !pip install git+https://github.com/facebookresearch/WavAugment\n!pip install torchaudio-augmentations\n\n# !wget http://opihi.cs.uvic.ca/sound/genres.tar.gz\n# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/train_filtered.txt\n# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/valid_filtered.txt\n# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/test_filtered.txt    \n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:30:47.145874Z","iopub.execute_input":"2023-02-13T17:30:47.146956Z","iopub.status.idle":"2023-02-13T17:31:01.315873Z","shell.execute_reply.started":"2023-02-13T17:30:47.146921Z","shell.execute_reply":"2023-02-13T17:31:01.314677Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torchaudio-augmentations\n  Downloading torchaudio_augmentations-0.2.4-py3-none-any.whl (12 kB)\nCollecting julius\n  Downloading julius-0.2.7.tar.gz (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting wavaugment\n  Downloading wavaugment-0.2-py3-none-any.whl (5.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchaudio-augmentations) (1.21.6)\nCollecting torch-pitch-shift\n  Downloading torch_pitch_shift-1.2.2-py3-none-any.whl (5.0 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchaudio-augmentations) (1.11.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (from torchaudio-augmentations) (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->torchaudio-augmentations) (4.1.1)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from torch-pitch-shift->torchaudio-augmentations) (21.3)\nCollecting primePy>=1.3\n  Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=21.3->torch-pitch-shift->torchaudio-augmentations) (3.0.9)\nBuilding wheels for collected packages: julius\n  Building wheel for julius (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21894 sha256=a653f87bb3ab6a556f55daaa894efe4640ff7e12c535f847fd19f99ecccf94ee\n  Stored in directory: /root/.cache/pip/wheels/44/52/2c/7dd069f82c7f905f40b190a8039ec2a17fdd4bb009c57c6664\nSuccessfully built julius\nInstalling collected packages: primePy, julius, wavaugment, torch-pitch-shift, torchaudio-augmentations\nSuccessfully installed julius-0.2.7 primePy-1.3 torch-pitch-shift-1.2.2 torchaudio-augmentations-0.2.4 wavaugment-0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#rename\ndef rname(fname):\n    dirnfile= fname.split('/')\n    directory = dirnfile[0]\n    f = dirnfile[1].split('.')\n    \n#     print(f)\n    file = f'{f[0]}_{f[0]}_{f[1]}.wav'\n#     print(file)\n    return file\n    \n#edit filtered\n# with open('/kaggle/working/train_filtered.txt') as f:\n#     lines = f.readlines()\n#     song_list = [line.strip() for line in lines]\n# #     rname(song_list[0])\n#     song_list_cleaned = map(rname, song_list)\n# #     print(list(song_list_cleaned))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:01.320012Z","iopub.execute_input":"2023-02-13T17:31:01.320368Z","iopub.status.idle":"2023-02-13T17:31:01.326471Z","shell.execute_reply.started":"2023-02-13T17:31:01.320332Z","shell.execute_reply":"2023-02-13T17:31:01.325354Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport numpy as np\nimport soundfile as sf\nimport librosa\nfrom torch.utils import data\nfrom torchaudio_augmentations import (\nRandomResizedCrop,\nRandomApply,\nPolarityInversion,\nNoise,\nGain,\nHighLowPass,\nDelay,\nPitchShift,\nReverb,\nCompose,\n)\n\n\nGTZAN_GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\nNEP_GENRES = ['classic','aadhunik','bhajan']\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:01.328351Z","iopub.execute_input":"2023-02-13T17:31:01.328752Z","iopub.status.idle":"2023-02-13T17:31:04.849553Z","shell.execute_reply.started":"2023-02-13T17:31:01.328714Z","shell.execute_reply":"2023-02-13T17:31:04.848475Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# sf.available_formats()","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:04.853279Z","iopub.execute_input":"2023-02-13T17:31:04.853793Z","iopub.status.idle":"2023-02-13T17:31:04.858363Z","shell.execute_reply.started":"2023-02-13T17:31:04.853761Z","shell.execute_reply":"2023-02-13T17:31:04.856927Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class GTZANDataset(data.Dataset):\n    def __init__(self, data_path, split, num_samples, num_chunks, is_augmentation):\n        self.data_path = data_path if data_path else ''\n        self.split = split\n        self.num_samples = num_samples\n        self.num_chunks = num_chunks\n        self.is_augmentation = is_augmentation\n        self.genres = GTZAN_GENRES\n        self.buffer = None\n        self._get_song_list()\n        \n        if is_augmentation:\n            self._get_augmentations()\n        \n    def _get_song_list(self):\n        list_filename = f'/kaggle/working/{self.split}_filtered.txt'\n        \n        with open(list_filename) as f:\n            lines = f.readlines()\n            song_list = [line.strip() for line in lines]\n            rname(song_list[0])\n            song_list_cleaned = map(rname, song_list)\n#             print(list(song_list_cleaned))\n            self.song_list = list(song_list_cleaned)\n        \n#         with open(list_filename) as f:\n#             lines = f.readlines()\n#         self.song_list = [line.strip() for line in lines]\n#         print(self.song_list)\n            \n    def _get_augmentations(self):\n        transforms = [\n            RandomResizedCrop(n_samples=self.num_samples),\n            RandomApply([PolarityInversion()], p=0.8),\n            RandomApply([Noise(min_snr=0.3, max_snr=0.5)], p=0.3),\n            RandomApply([Gain()], p=0.2),\n            RandomApply([HighLowPass(sample_rate=22050)], p=0.8),\n            RandomApply([Delay(sample_rate=22050)], p=0.5),\n            RandomApply([PitchShift(n_samples=self.num_samples, sample_rate=22050)], p=0.4),\n            RandomApply([Reverb(sample_rate=22050)], p=0.3),\n        ]\n        self.augmentation = Compose(transforms=transforms)\n            \n    def _adjust_audio_length(self, wav):\n        if self.split == 'train':\n            random_index = random.randint(0, len(wav) - self.num_samples - 1)\n            wav = wav[random_index : random_index + self.num_samples]\n        else:\n            hop = (len(wav) - self.num_samples) // self.num_chunks\n            wav = np.array([wav[i*hop: i*hop + self.num_samples] for i in range(self.num_chunks)])\n        return wav\n        \n    def __getitem__(self, index):\n        line= self.song_list[index]\n\n#         print(line)\n        #get genre\n        \n        genre_name = line.split('_')[0]\n#         print(genre_name)\n        genre_index = self.genres.index(genre_name)\n        \n        #get audio\n        audio_filename= os.path.join(self.data_path, 'genres_original',genre_name, line)\n#         print(audio_filename)\n#         wav, fs = sf.read(audio_filename)\n        try:\n            wav, fs = librosa.load(audio_filename)\n            \n            #adjust audio length\n            wav = self._adjust_audio_length(wav).astype('float32')\n\n            #data augmentation\n            if self.is_augmentation:\n                wav = self.augmentation(torch.from_numpy(wav).unsqueeze(0))\n            \n            self.buffer = (wav, genre_index)\n            \n            return wav, genre_index\n        \n        \n        except:\n            \n            print(\"bad file; return buffer file to batch\")\n            return self.buffer[0], self.buffer[1]\n            \n    \n#         except:\n#             print(\"bad file error\")\n#             return None\n        \n    def __len__(self):\n        return len(self.song_list)    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:04.859964Z","iopub.execute_input":"2023-02-13T17:31:04.860617Z","iopub.status.idle":"2023-02-13T17:31:04.878373Z","shell.execute_reply.started":"2023-02-13T17:31:04.860577Z","shell.execute_reply":"2023-02-13T17:31:04.877163Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class NepDataset(data.Dataset):\n    def __init__(self, data_path, split, num_samples, num_chunks, is_augmentation):\n        self.data_path = data_path if data_path else ''\n        self.split = split\n        self.num_samples = num_samples\n        self.num_chunks = num_chunks\n        self.is_augmentation = is_augmentation\n        self.genres = NEP_GENRES\n        self.buffer = None\n        self._get_song_list()\n        \n        if is_augmentation:\n            self._get_augmentations()\n        \n    def _get_song_list(self):\n        list_filename = f'/kaggle/input/nepali-music-genre-classification/Nep_Dataset/Nep_Dataset/{self.split}.txt'\n        \n        with open(list_filename) as f:\n            lines = f.readlines()\n            song_list = [line.strip() for line in lines]\n#             rname(song_list[0])\n#             song_list_cleaned = map(rname, song_list)\n#             print(list(song_list_cleaned))\n            print(song_list)\n            self.song_list = list(song_list)\n        \n#         with open(list_filename) as f:\n#             lines = f.readlines()\n#         self.song_list = [line.strip() for line in lines]\n#         print(self.song_list)\n            \n    def _get_augmentations(self):\n        transforms = [\n            RandomResizedCrop(n_samples=self.num_samples),\n            RandomApply([PolarityInversion()], p=0.8),\n            RandomApply([Noise(min_snr=0.3, max_snr=0.5)], p=0.3),\n            RandomApply([Gain()], p=0.2),\n            RandomApply([HighLowPass(sample_rate=22050)], p=0.8),\n            RandomApply([Delay(sample_rate=22050)], p=0.5),\n            RandomApply([PitchShift(n_samples=self.num_samples, sample_rate=22050)], p=0.4),\n            RandomApply([Reverb(sample_rate=22050)], p=0.3),\n        ]\n        self.augmentation = Compose(transforms=transforms)\n            \n    def _adjust_audio_length(self, wav):\n        if self.split == 'train':\n            random_index = random.randint(0, len(wav) - self.num_samples - 1)\n            wav = wav[random_index : random_index + self.num_samples]\n        else:\n            hop = (len(wav) - self.num_samples) // self.num_chunks\n            wav = np.array([wav[i*hop: i*hop + self.num_samples] for i in range(self.num_chunks)])\n        return wav\n        \n    def __getitem__(self, index):\n        line= self.song_list[index]\n\n#         print(line)\n        #get genre\n        \n        genre_name = line.split('_')[0]\n#         print(genre_name)\n        genre_index = self.genres.index(genre_name.split('/')[0])\n        \n        #get audio\n        audio_filename= os.path.join(self.data_path, line)\n        \n#         wav, fs = sf.read(audio_filename)\n        try:\n            wav, fs = librosa.load(audio_filename)\n#             print(audio_filename)\n            #adjust audio length\n            wav = self._adjust_audio_length(wav).astype('float32')\n            \n            #data augmentation\n            if self.is_augmentation:\n                wav = self.augmentation(torch.from_numpy(wav).unsqueeze(0))\n        \n            self.buffer = (wav, genre_index)\n            return wav, genre_index\n        \n        except:\n            \n            print(\"bad file; return buffer file to batch\")\n            return self.buffer[0], self.buffer[1]\n            \n    \n#         except:\n#             print(\"bad file error\")\n#             return None\n        \n    def __len__(self):\n        return len(self.song_list)    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:04.879887Z","iopub.execute_input":"2023-02-13T17:31:04.880288Z","iopub.status.idle":"2023-02-13T17:31:04.897562Z","shell.execute_reply.started":"2023-02-13T17:31:04.880240Z","shell.execute_reply":"2023-02-13T17:31:04.896316Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    batch = list(filter(lambda x: x is not None, batch))\n#     for item in batch:\n#         print('item ', item)\n#         tens = item[0]\n#         print(tens.shape)\n    batch = list(filter(lambda x: x[0].shape[-1] == 639450, batch))\n    print('collate_fn ')\n        \n#     print(\"collate_fn batch\", batch)\n    return torch.utils.data.dataloader.default_collate(batch)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:04.900293Z","iopub.execute_input":"2023-02-13T17:31:04.900578Z","iopub.status.idle":"2023-02-13T17:31:04.911345Z","shell.execute_reply.started":"2023-02-13T17:31:04.900553Z","shell.execute_reply":"2023-02-13T17:31:04.910234Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# #test to check wav lengths\n# buffer = None\n# for f in os.listdir('/kaggle/input/nepali-music-genre-classification/Nep_Dataset/aadhunik/'):\n#     try:\n#         print(f)\n#         wav, fs = librosa.load('/kaggle/input/nepali-music-genre-classification/Nep_Dataset/aadhunik/'+f)\n#         #adjust audio length\n# #         wav = self._adjust_audio_length(wav).astype('float32')\n\n#         #data augmentation\n# #         if self.is_augmentation:\n# #             wav = self.augmentation(torch.from_numpy(wav).unsqueeze(0))\n\n#         buffer = (wav, fs)\n\n#         print(len(wav), fs)\n        \n        \n#     except:\n\n#         print(\"bad file; return buffer file to batch\", f)\n#         print (buffer[0], buffer[1])\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T10:56:17.689438Z","iopub.execute_input":"2023-02-13T10:56:17.689797Z","iopub.status.idle":"2023-02-13T10:56:17.695149Z","shell.execute_reply.started":"2023-02-13T10:56:17.689767Z","shell.execute_reply":"2023-02-13T10:56:17.694083Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"#dataloader\ndef get_dataloader(data_path='/kaggle/input/nepali-music-genre-classification/Nep_Dataset/Nep_Dataset',\n                  split='train',\n                  num_samples=22050*29,\n                  num_chunks=1,\n                  batch_size=16,\n#                    batch_size=1,\n                  num_workers=0,\n                  is_augmentation=False):\n    is_shuffle = True if (split == 'train') else False\n    \n    batch_size = batch_size if (split=='train') else (batch_size//num_chunks)\n    data_loader = data.DataLoader(dataset=NepDataset(data_path,\n                                                      split,\n                                                      num_samples,\n                                                      num_chunks,\n                                                      is_augmentation),\n                                 batch_size = batch_size,\n                                 shuffle=is_shuffle,\n                                 drop_last=False,\n                                 num_workers=num_workers,\n                                 collate_fn=collate_fn)\n    \n    return data_loader\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:04.914951Z","iopub.execute_input":"2023-02-13T17:31:04.915460Z","iopub.status.idle":"2023-02-13T17:31:04.923344Z","shell.execute_reply.started":"2023-02-13T17:31:04.915425Z","shell.execute_reply":"2023-02-13T17:31:04.922176Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader = get_dataloader(split='train', is_augmentation=True)\niter_train_loader = iter(train_loader)\ntrain_wav, train_genre = next(iter_train_loader)\n\nvalid_loader = get_dataloader(split='valid')\ntest_loader = get_dataloader(split='test')\niter_test_loader = iter(test_loader)\n\ntest_wav, test_genre = next(iter_test_loader)\nprint('training data shape: %s' %str(train_wav.shape))\nprint('validation/test data shape: %s' %str(test_wav.shape))\nprint(train_genre)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:31:37.567507Z","iopub.execute_input":"2023-02-13T17:31:37.567945Z","iopub.status.idle":"2023-02-13T17:32:20.096350Z","shell.execute_reply.started":"2023-02-13T17:31:37.567909Z","shell.execute_reply":"2023-02-13T17:32:20.094942Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"['bhajan/bhajan_0.wav', 'bhajan/bhajan_1.wav', 'bhajan/bhajan_10.wav', 'bhajan/bhajan_11.wav', 'bhajan/bhajan_12.wav', 'bhajan/bhajan_13.wav', 'bhajan/bhajan_14.wav', 'bhajan/bhajan_15.wav', 'bhajan/bhajan_16.wav', 'bhajan/bhajan_17.wav', 'bhajan/bhajan_18.wav', 'bhajan/bhajan_19.wav', 'bhajan/bhajan_2.wav', 'bhajan/bhajan_20.wav', 'bhajan/bhajan_21.wav', 'bhajan/bhajan_22.wav', 'bhajan/bhajan_23.wav', 'bhajan/bhajan_24.wav', 'bhajan/bhajan_25.wav', 'bhajan/bhajan_26.wav', 'bhajan/bhajan_27.wav', 'bhajan/bhajan_28.wav', 'bhajan/bhajan_29.wav', 'bhajan/bhajan_3.wav', 'bhajan/bhajan_4.wav', 'bhajan/bhajan_40.wav', 'bhajan/bhajan_50.wav', 'bhajan/bhajan_51.wav', 'bhajan/bhajan_52.wav', 'bhajan/bhajan_53.wav', 'bhajan/bhajan_54.wav', 'bhajan/bhajan_55.wav', 'bhajan/bhajan_56.wav', 'bhajan/bhajan_57.wav', 'bhajan/bhajan_58.wav', 'bhajan/bhajan_59.wav', 'bhajan/bhajan_6.wav', 'bhajan/bhajan_60.wav', 'bhajan/bhajan_61.wav', 'bhajan/bhajan_62.wav', 'bhajan/bhajan_63.wav', 'bhajan/bhajan_64.wav', 'bhajan/bhajan_65.wav', 'bhajan/bhajan_66.wav', 'bhajan/bhajan_67.wav', 'bhajan/bhajan_68.wav', 'bhajan/bhajan_69.wav', 'bhajan/bhajan_7.wav', 'bhajan/bhajan_70.wav', 'bhajan/bhajan_80.wav', 'bhajan/bhajan_81.wav', 'bhajan/bhajan_82.wav', 'bhajan/bhajan_83.wav', 'bhajan/bhajan_84.wav', 'bhajan/bhajan_85.wav', 'bhajan/bhajan_86.wav', 'bhajan/bhajan_87.wav', 'bhajan/bhajan_88.wav', 'bhajan/bhajan_89.wav', 'bhajan/bhajan_9.wav', 'bhajan/bhajan_90.wav', 'bhajan/bhajan_91.wav', 'bhajan/bhajan_92.wav', 'bhajan/bhajan_93.wav', 'bhajan/bhajan_94.wav', 'bhajan/bhajan_95.wav', 'bhajan/bhajan_96.wav', 'bhajan/bhajan_97.wav', 'bhajan/bhajan_98.wav', 'bhajan/bhajan_99.wav', 'classic/classic_0.wav', 'classic/classic_1.wav', 'classic/classic_10.wav', 'classic/classic_11.wav', 'classic/classic_12.wav', 'classic/classic_13.wav', 'classic/classic_14.wav', 'classic/classic_15.wav', 'classic/classic_16.wav', 'classic/classic_17.wav', 'classic/classic_18.wav', 'classic/classic_19.wav', 'classic/classic_2.wav', 'classic/classic_20.wav', 'classic/classic_30.wav', 'classic/classic_31.wav', 'classic/classic_32.wav', 'classic/classic_33.wav', 'classic/classic_34.wav', 'classic/classic_35.wav', 'classic/classic_36.wav', 'classic/classic_37.wav', 'classic/classic_38.wav', 'classic/classic_39.wav', 'classic/classic_4.wav', 'classic/classic_40.wav', 'classic/classic_41.wav', 'classic/classic_42.wav', 'classic/classic_43.wav', 'classic/classic_44.wav', 'classic/classic_45.wav', 'classic/classic_46.wav', 'classic/classic_47.wav', 'classic/classic_48.wav', 'classic/classic_49.wav', 'classic/classic_5.wav', 'classic/classic_6.wav', 'classic/classic_60.wav', 'classic/classic_61.wav', 'classic/classic_62.wav', 'classic/classic_63.wav', 'classic/classic_64.wav', 'classic/classic_65.wav', 'classic/classic_66.wav', 'classic/classic_67.wav', 'classic/classic_68.wav', 'classic/classic_69.wav', 'classic/classic_7.wav', 'classic/classic_70.wav', 'classic/classic_71.wav', 'classic/classic_72.wav', 'classic/classic_73.wav', 'classic/classic_74.wav', 'classic/classic_75.wav', 'classic/classic_76.wav', 'classic/classic_77.wav', 'classic/classic_78.wav', 'classic/classic_79.wav', 'classic/classic_8.wav', 'classic/classic_9.wav', 'classic/classic_90.wav', 'classic/classic_91.wav', 'classic/classic_92.wav', 'classic/classic_93.wav', 'classic/classic_94.wav', 'classic/classic_95.wav', 'classic/classic_96.wav', 'classic/classic_97.wav', 'classic/classic_98.wav', 'classic/classic_99.wav', 'aadhunik/aadhunik_0.wav', 'aadhunik/aadhunik_19.wav', 'aadhunik/aadhunik_2.wav', 'aadhunik/aadhunik_20.wav', 'aadhunik/aadhunik_21.wav', 'aadhunik/aadhunik_22.wav', 'aadhunik/aadhunik_23.wav', 'aadhunik/aadhunik_24.wav', 'aadhunik/aadhunik_25.wav', 'aadhunik/aadhunik_26.wav', 'aadhunik/aadhunik_27.wav', 'aadhunik/aadhunik_28.wav', 'aadhunik/aadhunik_29.wav', 'aadhunik/aadhunik_3.wav', 'aadhunik/aadhunik_30.wav', 'aadhunik/aadhunik_31.wav', 'aadhunik/aadhunik_32.wav', 'aadhunik/aadhunik_33.wav', 'aadhunik/aadhunik_34.wav', 'aadhunik/aadhunik_35.wav', 'aadhunik/aadhunik_36.wav', 'aadhunik/aadhunik_37.wav', 'aadhunik/aadhunik_38.wav', 'aadhunik/aadhunik_39.wav', 'aadhunik/aadhunik_4.wav', 'aadhunik/aadhunik_40.wav', 'aadhunik/aadhunik_41.wav', 'aadhunik/aadhunik_42.wav', 'aadhunik/aadhunik_43.wav', 'aadhunik/aadhunik_44.wav', 'aadhunik/aadhunik_45.wav', 'aadhunik/aadhunik_46.wav', 'aadhunik/aadhunik_47.wav', 'aadhunik/aadhunik_48.wav', 'aadhunik/aadhunik_49.wav', 'aadhunik/aadhunik_5.wav', 'aadhunik/aadhunik_6.wav', 'aadhunik/aadhunik_60.wav', 'aadhunik/aadhunik_61.wav', 'aadhunik/aadhunik_62.wav', 'aadhunik/aadhunik_63.wav', 'aadhunik/aadhunik_64.wav', 'aadhunik/aadhunik_65.wav', 'aadhunik/aadhunik_66.wav', 'aadhunik/aadhunik_67.wav', 'aadhunik/aadhunik_68.wav', 'aadhunik/aadhunik_69.wav', 'aadhunik/aadhunik_7.wav', 'aadhunik/aadhunik_70.wav', 'aadhunik/aadhunik_71.wav', 'aadhunik/aadhunik_72.wav', 'aadhunik/aadhunik_73.wav', 'aadhunik/aadhunik_74.wav', 'aadhunik/aadhunik_75.wav', 'aadhunik/aadhunik_76.wav', 'aadhunik/aadhunik_77.wav', 'aadhunik/aadhunik_78.wav', 'aadhunik/aadhunik_79.wav', 'aadhunik/aadhunik_89.wav', 'aadhunik/aadhunik_9.wav', 'aadhunik/aadhunik_90.wav', 'aadhunik/aadhunik_91.wav', 'aadhunik/aadhunik_92.wav', 'aadhunik/aadhunik_93.wav', 'aadhunik/aadhunik_94.wav', 'aadhunik/aadhunik_95.wav', 'aadhunik/aadhunik_96.wav', 'aadhunik/aadhunik_97.wav', 'aadhunik/aadhunik_98.wav', 'aadhunik/aadhunik_99.wav']\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\ncollate_fn \n['bhajan/bhajan_41.wav', 'bhajan/bhajan_42.wav', 'bhajan/bhajan_43.wav', 'bhajan/bhajan_44.wav', 'bhajan/bhajan_45.wav', 'bhajan/bhajan_46.wav', 'bhajan/bhajan_47.wav', 'bhajan/bhajan_48.wav', 'bhajan/bhajan_49.wav', 'bhajan/bhajan_5.wav', 'classic/classic_50.wav', 'classic/classic_51.wav', 'classic/classic_52.wav', 'classic/classic_53.wav', 'classic/classic_54.wav', 'classic/classic_55.wav', 'classic/classic_56.wav', 'classic/classic_57.wav', 'classic/classic_58.wav', 'classic/classic_59.wav', 'aadhunik/aadhunik_8.wav', 'aadhunik/aadhunik_80.wav', 'aadhunik/aadhunik_81.wav', 'aadhunik/aadhunik_82.wav', 'aadhunik/aadhunik_83.wav', 'aadhunik/aadhunik_84.wav', 'aadhunik/aadhunik_85.wav', 'aadhunik/aadhunik_86.wav', 'aadhunik/aadhunik_87.wav', 'aadhunik/aadhunik_88.wav']\n['bhajan/bhajan_30.wav', 'bhajan/bhajan_31.wav', 'bhajan/bhajan_32.wav', 'bhajan/bhajan_33.wav', 'bhajan/bhajan_34.wav', 'bhajan/bhajan_35.wav', 'bhajan/bhajan_36.wav', 'bhajan/bhajan_37.wav', 'bhajan/bhajan_38.wav', 'bhajan/bhajan_39.wav', 'bhajan/bhajan_71.wav', 'bhajan/bhajan_72.wav', 'bhajan/bhajan_73.wav', 'bhajan/bhajan_74.wav', 'bhajan/bhajan_75.wav', 'bhajan/bhajan_76.wav', 'bhajan/bhajan_77.wav', 'bhajan/bhajan_78.wav', 'bhajan/bhajan_79.wav', 'bhajan/bhajan_8.wav', 'classic/classic_80.wav', 'classic/classic_81.wav', 'classic/classic_82.wav', 'classic/classic_83.wav', 'classic/classic_84.wav', 'classic/classic_85.wav', 'classic/classic_86.wav', 'classic/classic_87.wav', 'classic/classic_88.wav', 'classic/classic_89.wav', 'classic/classic_21.wav', 'classic/classic_22.wav', 'classic/classic_23.wav', 'classic/classic_24.wav', 'classic/classic_25.wav', 'classic/classic_26.wav', 'classic/classic_27.wav', 'classic/classic_28.wav', 'classic/classic_29.wav', 'classic/classic_3.wav', 'aadhunik/aadhunik_1.wav', 'aadhunik/aadhunik_10.wav', 'aadhunik/aadhunik_11.wav', 'aadhunik/aadhunik_12.wav', 'aadhunik/aadhunik_13.wav', 'aadhunik/aadhunik_14.wav', 'aadhunik/aadhunik_15.wav', 'aadhunik/aadhunik_16.wav', 'aadhunik/aadhunik_17.wav', 'aadhunik/aadhunik_18.wav', 'aadhunik/aadhunik_50.wav', 'aadhunik/aadhunik_51.wav', 'aadhunik/aadhunik_52.wav', 'aadhunik/aadhunik_53.wav', 'aadhunik/aadhunik_54.wav', 'aadhunik/aadhunik_55.wav', 'aadhunik/aadhunik_56.wav', 'aadhunik/aadhunik_57.wav', 'aadhunik/aadhunik_58.wav', 'aadhunik/aadhunik_59.wav']\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntraining data shape: torch.Size([16, 1, 639450])\nvalidation/test data shape: torch.Size([16, 1, 639450])\ntensor([0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model\nfrom torch import nn\n\nclass Conv_2d(nn.Module):\n    def __init__(self, input_channels, output_channels, shape=3, pooling=2, dropout=0.1):\n        super(Conv_2d, self).__init__()\n        self.conv = nn.Conv2d(input_channels, output_channels, shape, padding=shape//2)\n        self.bn = nn.BatchNorm2d(output_channels)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(pooling)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, wav):\n        out= self.conv(wav)\n        out= self.bn(out)\n        out= self.relu(out)\n        out= self.maxpool(out)\n        out= self.dropout(out)\n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:32:23.405832Z","iopub.execute_input":"2023-02-13T17:32:23.406223Z","iopub.status.idle":"2023-02-13T17:32:23.414794Z","shell.execute_reply.started":"2023-02-13T17:32:23.406186Z","shell.execute_reply":"2023-02-13T17:32:23.413712Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from PIL import Image\n# import torchvision.transforms as T\n\n# def save_test_spec(testing):\n# # testing = torch.randn((16,1,128,1249))\n# #     print(testing.shape)\n#     stripped_test = testing.squeeze(1)\n# #     print(stripped_test[0].shape)\n#     new = stripped_test[0]\n#     new = new.unsqueeze(0)\n# # print(new.shape)\n#     transform = T.ToPILImage()\n#     img = transform(new)\n#     img.save('/kaggle/working/test.png')","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:32:24.967019Z","iopub.execute_input":"2023-02-13T17:32:24.967601Z","iopub.status.idle":"2023-02-13T17:32:24.972145Z","shell.execute_reply.started":"2023-02-13T17:32:24.967566Z","shell.execute_reply":"2023-02-13T17:32:24.971063Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torchaudio\n\nclass CNN(nn.Module):\n    def __init__(self, num_channels=16,\n              sample_rate = 22050,\n              n_fft=1024,\n              f_min=0.0,\n              f_max=11025.0,\n              num_mels=128,\n              num_classes=10):\n        \n        super(CNN,self).__init__()\n        \n        #mel spectrogram\n        self.melspec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n                                                           n_fft=n_fft,\n                                                           f_min=f_min,\n                                                           f_max=f_max,\n                                                           n_mels=num_mels) \n        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB()  #cepstral coefficients\n        self.input_bn = nn.BatchNorm2d(1)\n        \n        #convolutional layers\n        self.layer1 = Conv_2d(1, num_channels, pooling=(2,3))\n        self.layer2 = Conv_2d(num_channels, num_channels, pooling=(3,4))\n        self.layer3 = Conv_2d(num_channels, num_channels*2, pooling=(2,5))\n        self.layer4 = Conv_2d(num_channels*2, num_channels*2, pooling=(3,3))\n        self.layer5 = Conv_2d(num_channels*2, num_channels*4, pooling=(3,4))\n        \n        #dense layers\n        self.dense1 = nn.Linear(num_channels*4, num_channels*4)\n        self.dense_bn = nn.BatchNorm1d(num_channels*4)\n        self.dense2 = nn.Linear(num_channels*4, num_classes) #maybe try softmax here\n        self.dropout = nn.Dropout(0.5)\n        self.relu = nn.ReLU()\n        \n        \n    def forward(self,wav):\n        #input processing\n        \n#         print(wav.shape)\n        out = self.melspec(wav)\n#         print(out.shape)\n#         copy = torch.clone(out)\n#         copy.to('cpu')\n#         save_test_spec(copy)\n        \n        out = self.amplitude_to_db(out)\n        #input batch\n#       out = out.unsqueeze(1)\n#         print(out.shape)\n#         out = torch.permute(out, (0,3,2,1))\n#         print(out.shape)\n        out = self.input_bn(out)\n#         print(out.shape)\n\n        #convlayers\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n\n        # reshape. (batch_size, num_channels, 1, 1) -> (batch_size, num_channels)\n        out = out.reshape(len(out), -1)\n\n        #dense layers\n        out = self.dense1(out)\n        out = self.dense_bn(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.dense2(out)\n        \n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:33:30.995568Z","iopub.execute_input":"2023-02-13T17:33:30.995939Z","iopub.status.idle":"2023-02-13T17:33:31.008449Z","shell.execute_reply.started":"2023-02-13T17:33:30.995906Z","shell.execute_reply":"2023-02-13T17:33:31.007405Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#transform for resnet18 model\nimport torchaudio\nfrom PIL import Image\nfrom torchvision import transforms\n\n# input_image = Image.open(filename)\n# preprocess = transforms.Compose([\n#     transforms.Resize((224, 1249)),\n# #     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n# ])\n# input_tensor = preprocess(input_image)\n# input_batch = input_tensor.unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:33:36.568178Z","iopub.execute_input":"2023-02-13T17:33:36.568914Z","iopub.status.idle":"2023-02-13T17:33:36.955791Z","shell.execute_reply.started":"2023-02-13T17:33:36.568876Z","shell.execute_reply":"2023-02-13T17:33:36.954673Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#lets try resnet\n\nclass CNN_modified(nn.Module):\n    def __init__(self, num_channels=16,\n              sample_rate = 22050,\n              n_fft=1024,\n              f_min=0.0,\n              f_max=11025.0,\n              num_mels=128,\n              num_classes=10):\n        \n        super(CNN_modified,self).__init__()\n        \n        #mel spectrogram\n        self.melspec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n                                                           n_fft=n_fft,\n                                                           f_min=f_min,\n                                                           f_max=f_max,\n                                                           n_mels=num_mels) \n        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB()  #cepstral coefficients\n        self.input_bn = nn.BatchNorm2d(1)\n        self.resnet_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n        self.resnet_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False) #changed no of input channels\n\n        \n        #convolutional layers\n#         self.layer1 = Conv_2d(1, num_channels, pooling=(2,3))\n#         self.layer2 = Conv_2d(num_channels, num_channels, pooling=(3,4))\n#         self.layer3 = Conv_2d(num_channels, num_channels*2, pooling=(2,5))\n#         self.layer4 = Conv_2d(num_channels*2, num_channels*2, pooling=(3,3))\n#         self.layer5 = Conv_2d(num_channels*2, num_channels*4, pooling=(3,4))\n#         self.layer1 = self.resnet_model()\n    \n        #dense layers\n#         self.dense1 = nn.Linear(num_channels*4, num_channels*4)\n#         self.dense_bn = nn.BatchNorm1d(num_channels*4)\n#         self.dense2 = nn.Linear(num_channels*4, num_classes) #maybe try softmax here\n#         self.dropout = nn.Dropout(0.5)\n#         self.relu = nn.ReLU()\n        \n        \n    def forward(self,wav):\n        #input processing\n        \n#         print(wav.shape)\n        out = self.melspec(wav)\n#         print(out.shape)\n#         copy = torch.clone(out)\n#         copy.to('cpu')\n#         save_test_spec(copy)\n        out = self.amplitude_to_db(out)\n        #input batch\n        \n#       out = out.unsqueeze(1)\n#         print(out.shape)\n#         out = torch.permute(out, (0,3,2,1))\n#         print(out.shape)\n        out = self.input_bn(out)\n#         print(out.shape)\n        \n        \n        \n        #convlayers\n        print(out.shape)\n        out = self.resnet_model(out)\n#         out = self.layer2(out)\n#         out = self.layer3(out)\n#         out = self.layer4(out)\n#         out = self.layer5(out)\n#         out = self.resnet_model(out) #trying directly without normalizing inputs or the shape of image\n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:33:37.799690Z","iopub.execute_input":"2023-02-13T17:33:37.800298Z","iopub.status.idle":"2023-02-13T17:33:37.813361Z","shell.execute_reply.started":"2023-02-13T17:33:37.800233Z","shell.execute_reply":"2023-02-13T17:33:37.812507Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# cnn = CNN().to(device)\ncnn = CNN_modified().to(device)\nloss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\nvalid_losses = []\nnum_epochs = 70","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:33:43.422255Z","iopub.execute_input":"2023-02-13T17:33:43.422641Z","iopub.status.idle":"2023-02-13T17:33:47.495637Z","shell.execute_reply.started":"2023-02-13T17:33:43.422611Z","shell.execute_reply":"2023-02-13T17:33:47.494654Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"#training\nfor epoch in range(num_epochs):\n    train_losses = []\n    \n    #Train\n    cnn.train()\n    for (wav, genre_index) in train_loader:\n        wav = wav.to(device)\n        genre_index = genre_index.to(device)\n\n        #forward\n        out= cnn(wav)\n        loss= loss_function(out, genre_index)\n\n        #backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())\n\n        mean_train_losses = np.mean(train_losses)\n    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, mean_train_losses))\n    \n    \n    #validation\n    cnn.eval()\n    y_true = []\n    y_pred = []\n    valid_losses = []\n    \n    for wav, genre_index in valid_loader:\n        wav = wav.to(device)\n        genre_index = genre_index.to(device)\n\n        #reshape and aggregate chunk-level predictions\n        b, c, t = wav.size()\n        \n        check = wav.view(-1,t)\n#         print(check.shape)\n        \n#         logits = cnn(wav.view(-1,t))\n        logits = cnn(wav)\n        logits = logits.view(b, c, -1).mean(dim=1)\n        loss = loss_function(logits, genre_index)\n        valid_losses.append(loss.item())\n        _, pred = torch.max(logits.data,1)\n\n\n        #append\n        y_true.extend(genre_index.tolist())\n        y_pred.extend(pred.tolist())\n    accuracy = accuracy_score(y_true, y_pred)\n    valid_loss = np.mean(valid_losses)\n    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n        \n    #save model\n    valid_losses.append(valid_loss.item())\n#     if(epoch%2 == 0):\n    name = 'model_'+ str(epoch)+'.ckpt'\n    torch.save(cnn.state_dict(),name)\n#     if np.argmin(valid_losses) == epoch:\n#         print('Saving the best model at %d epochs!' % epoch)\n#         torch.save(cnn.state_dict(), 'best_model.ckpt')\n    \n    wandb.log({\"train_loss\": mean_train_losses, \"valid_loss\":valid_loss, \"accuracy\":accuracy})\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T11:08:52.481817Z","iopub.execute_input":"2023-02-13T11:08:52.482781Z","iopub.status.idle":"2023-02-13T11:14:26.488472Z","shell.execute_reply.started":"2023-02-13T11:08:52.482729Z","shell.execute_reply":"2023-02-13T11:14:26.486761Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\nbad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\nbad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\nbad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\ncollate_fn \ntorch.Size([2, 1, 128, 1249])\nEpoch: [1/70], Train loss: 2.9277\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"bad file; return buffer file to batch\nbad file; return buffer file to batch\ncollate_fn \ntorch.Size([16, 1, 128, 1249])\nbad file; return buffer file to batch\nbad file; return buffer file to batch\ncollate_fn \ntorch.Size([14, 1, 128, 1249])\nEpoch: [1/70], Valid loss: 1.6318, Valid accuracy 0.3667\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3112177825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#         torch.save(cnn.state_dict(), 'best_model.ckpt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean_train_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid_loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"],"ename":"NameError","evalue":"name 'wandb' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %debug\n#evaluation\n\nS = torch.load('/kaggle/input/nepali-music-genre-classification/model_61.ckpt')\n# print(S)\ncnn.load_state_dict(S, strict=False)\n\nprint('loaded!')\n\n#Run evaluation\n\ncnn.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for wav, genre_index in test_loader:\n        wav = wav.to(device)\n        genre_index = genre_index.to(device)\n        \n        #reshape and aggregate chunk- level predictions\n        b, c, t = wav.size()\n#         print(\"b,c,t\",b,c,t)\n#         logits = cnn(wav.view(-1, t))\n        print(\"wav.view(-1,t).shape\",wav.view(-1,t).shape)\n        logits = cnn(wav)\n#         print(\"logits\", logits)\n#         logits = logits.view(b, c, -1).mean(dim=1)\n#         print(\"logits data\",logits.data)\n        _, pred = torch.max(logits.data, 1)\n#         print(\"predictions\", pred)\n        #append labels and predictions\n        y_true.extend(genre_index.tolist())\n        y_pred.extend(pred.tolist())\n#         print(y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:46:42.742209Z","iopub.execute_input":"2023-02-13T17:46:42.742925Z","iopub.status.idle":"2023-02-13T17:47:45.809400Z","shell.execute_reply.started":"2023-02-13T17:46:42.742889Z","shell.execute_reply":"2023-02-13T17:47:45.807957Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"loaded!\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \nwav.view(-1,t).shape torch.Size([16, 639450])\ntorch.Size([16, 1, 128, 1249])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n  return f(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"collate_fn \nwav.view(-1,t).shape torch.Size([16, 639450])\ntorch.Size([16, 1, 128, 1249])\nbad file; return buffer file to batch\nbad file; return buffer file to batch\nbad file; return buffer file to batch\ncollate_fn \nwav.view(-1,t).shape torch.Size([12, 639450])\ntorch.Size([12, 1, 128, 1249])\ncollate_fn \nwav.view(-1,t).shape torch.Size([12, 639450])\ntorch.Size([12, 1, 128, 1249])\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# print(y_true, y_pred)\naccuracy = accuracy_score(y_true, y_pred)\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, xticklabels=NEP_GENRES, yticklabels=NEP_GENRES, cmap='YlGnBu')\nprint('Accuracy: %.4f' % accuracy)\n\n#model_24 -> 87.5% accuracy\n#model_31 -> 94.64% accuracy\n#model_32 -> 83.93% accuracy\n#model_37 -> 96.43% accuracy\n#model_44 -> 89.29% accuracy\n#model_55 -> 92.86% accuracy\n#model_61 -> 92.86% accuracy","metadata":{"execution":{"iopub.status.busy":"2023-02-13T17:47:50.056884Z","iopub.execute_input":"2023-02-13T17:47:50.058018Z","iopub.status.idle":"2023-02-13T17:47:50.335196Z","shell.execute_reply.started":"2023-02-13T17:47:50.057950Z","shell.execute_reply":"2023-02-13T17:47:50.334056Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Accuracy: 0.9286\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}